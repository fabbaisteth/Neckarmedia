# Neckarmedia Chatbot

Ein AI-gest√ºtzter Chatbot f√ºr Neckarmedia, der Kunden auf Ihrer Website √ºber das Unternehmen informiert.

## ‚ú® Features

- üöÄ **√ñffentlich zug√§nglich** - Keine Anmeldung erforderlich
- üîí **Sicher** - Rate Limiting, Input Validation, CORS Protection
- üéØ **Einfach zu deployen** - Docker-ready, cloud-ready
- üí¨ **Intelligente Antworten** - RAG-basiert mit Firmenwissen von Neckarmedia
- üåê **Website-Integration** - Einfach einbettbar in jede Website

## üöÄ Quick Start

**Lokales Testen in 2 Minuten:**

```bash
# 1. Umgebungsvariablen setzen
cp .env.example .env
# Editiere .env und f√ºge deinen OPENAI_API_KEY ein

# 2. Mit Docker starten
docker-compose up -d

# 3. Testen
curl http://localhost:8000/health
```

**Vollst√§ndige Anleitung:** Siehe [QUICK_START.md](QUICK_START.md)

## üìö Dokumentation

- **[QUICK_START.md](QUICK_START.md)** - In 5 Minuten loslegen
- **[PUBLIC_DEPLOYMENT.md](PUBLIC_DEPLOYMENT.md)** - Vollst√§ndiger Deployment-Guide f√ºr √∂ffentliche Website
- **[API_README.md](API_README.md)** - API Dokumentation

## üìù Beispiel-Fragen

- "Who founded Neckarmedia?"
- "Who is Karla?"
- "What is the workflow Neckarmedia has?"
- "What are the latest job offerings?"
- "Give two examples of Neckarmedia's references."

## üîß Entwicklung

```bash
# Virtuelle Umgebung aktivieren
source neckarvenv/bin/activate

# API starten
python api.py

# Gradio UI starten (optional)
python gradio_app.py
```

## üìñ System Architecture

### Scripts Overview

The chatbot system consists of several scripts that work together to create embeddings and enable the agent:

#### Data Collection & Processing Scripts

- **`services/crawl_blog.py`** - Crawls blog posts from Neckarmedia website and saves to `data/blog_posts.json`
- **`services/db_sql.py`** - Initializes SQLite database schema (`neckarmedia.db`)
- **`services/insert_blog_db.py`** - Inserts blog articles into database with AI-generated summaries and keywords
- **`services/generate_embeddings_db.py`** - Generates vector embeddings for semantic search
- **`services/handle_gdrive.py`** - Downloads and processes documents from Google Drive (optional)

#### Agent & API Scripts

- **`services/agent.py`** - Main agent that processes queries and generates responses using multiple tools
- **`api.py`** - FastAPI REST API server with rate limiting and security
- **`gradio_app.py`** - Web UI for testing (optional)

#### Utility Scripts

- **`services/keyword_list.py`** - Extracts unique keywords from database for analysis

### File Requirements

#### Required Data Files

1. **`data/services.json`** - Service descriptions, workflow, and FAQs
   - Format: JSON with `about`, `services`, `workflow`, and `faqs` sections
   - Used by agent to answer service-related questions

2. **`data/latest_info.json`** - Employee and founder information
   - Format: JSON with `founders` and `employees` objects
   - Used by agent to answer questions about people

3. **`data/blog_posts.json`** - Crawled blog posts (generated by `crawl_blog.py`)
   - Format: Array of objects with `url`, `title`, `content`, `date`
   - Imported into database by `insert_blog_db.py`

4. **`data/docs/`** - Local document files (optional)
   - Contains: `Karla.docx`, `Mitarbeiter Kontext Neckarmedia.docx`, `Onlinemarketing.docx`, etc.
   - Can be processed by `handle_gdrive.py` if needed

#### Google Drive Folder

- **Folder ID:** `1af9TUTNrBSkaoHZrSyqYWSTYqk0UiER3` (configured in `handle_gdrive.py`)
- **Required:** PDF and DOCX files
- **API Key:** Set `GOOGLE_DRIVE_API` in `.env`
- **Note:** Currently not actively used by main agent, but infrastructure exists

#### Database Files

- **`neckarmedia.db`** - SQLite database with blog articles and embeddings
  - Created by `db_sql.py` (schema)
  - Populated by `insert_blog_db.py` (data)
  - Enhanced by `generate_embeddings_db.py` (embeddings)

### Data Formats

#### `services.json` Format
```json
{
  "about": "Company description...",
  "services": {
    "digital_analytics": { "description": "..." },
    "seo": { "description": "..." },
    ...
  },
  "workflow": {
    "kennenlernen_problemverstaendnis": "Description...",
    ...
  },
  "faqs": {
    "was_unterscheidet_neckarmedia": "Answer...",
    ...
  }
}
```

#### `latest_info.json` Format
```json
{
  "founders": {
    "Kay": "Description...",
    "Johannes": "Description..."
  },
  "employees": {
    "Karla": "Description...",
    ...
  }
}
```

### Setup Workflow

The scripts execute in this sequence to create embeddings and set up the agent:

1. **Database Setup**
   ```bash
   python services/db_sql.py  # Creates schema
   ```

2. **Blog Crawling**
   ```bash
   python services/crawl_blog.py  # Generates blog_posts.json
   ```

3. **Database Population**
   ```bash
   python services/insert_blog_db.py  # Inserts articles with summaries/keywords
   ```

4. **Embedding Generation**
   ```bash
   python services/generate_embeddings_db.py  # Creates vector embeddings
   ```

5. **Agent Ready**
   ```bash
   python api.py  # Start API server
   ```

### How Scripts Connect

```
crawl_blog.py ‚Üí blog_posts.json
                    ‚Üì
            insert_blog_db.py ‚Üí neckarmedia.db (with summaries/keywords)
                    ‚Üì
        generate_embeddings_db.py ‚Üí neckarmedia.db (with embeddings)
                    ‚Üì
                    ‚Üì
            agent.py ‚Üê services.json + latest_info.json
                    ‚Üì
                  api.py ‚Üí User queries
```

**Query Flow:**
1. User sends query ‚Üí `api.py`
2. `api.py` calls ‚Üí `agent.py`
3. `agent.py` decides tool (LLM-based selection)
4. Tool retrieves data:
   - Blog search: Vector similarity search in `neckarmedia.db`
   - Employee info: Loads `latest_info.json`
   - Services: Loads `services.json`
   - Jobs: Live scraping from website
5. Context sent to GPT ‚Üí Response generated
6. Response returned to user via `api.py`

**For detailed architecture documentation, see [ARCHITECTURE.md](ARCHITECTURE.md)**

## API set up

1. Set an A record pointing to the IP of the chatbot machine
2. Start the API using a systemctl service

```bash
[Unit]
Description={yourname} fastapi
After=network-online.target
[Service]
WorkingDirectory=/home/{Repo}
EnvironmentFile=-/home/{Repo}/.env
ExecStart=/home/{Repo}/venv/bin/uvicorn api:app --host 127.0.0.1 --port 8000 --workers 2
Restart=always
User=root
Group=root
[Install]
WantedBy=multi-user.target
```

Then run this to start the service

```bash
sudo systemctl daemon-reload
sudo systemctl restart you-service-name
```
